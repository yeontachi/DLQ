# Introduction
## GPU 사용의 이점
오늘날의 컴퓨팅 환경에서 GPU(Graphics Processing Unit)는 CPU에 비해 훨씬 더 높은 **명령어 처리량(instruction throughput)**과 **메모리 대역폭(memory bandwidth)**을 제공한다. 놀라운 점은 이러한 성능을 비슷한 가격과 전력 소모 한계 내에서 제공한다는 것이다. 바로 이 점 때문에 많은 응용 프로그램들이 CPU보다 GPU 위에서 더 빠르게 실행될 수 있다.

물론 GPU만이 유일한 선택지는 아니다. 예를 들어 FPGA(Field Programmable Gate Array)는 매우 에너지 효율적이지만, 프로그래밍 유연성 측면에서는 GPU보다 훨씬 제한적이다. 따라서 범용적이고 쉽게 활용할 수 있는 고성능 연산 장치로 GPU가 각광을 받게 될 것이다.

### CPU와 GPU의 설계 목표 차이
CPU와 GPU가 제공하는 성능 차이는 이들이 **서로 다른 목표**를 두고 설계되었기 때문이다.
 - **CPU**는 가능한 빠르게 하나의 실행 흐름(스레드)을 처리하도록 최적화되어 있다. 따라서 CPU는 복잡한 제어, 분기 예측, 큰 캐시 등을 이용해 수십 개 정도의 스레드를 병렬로 실행하는 데 강점을 보인다.
 - **GPU**는 수천 개의 스레드를 동시에 실행하도록 설계되어 있다. 즉, 단일 스레드 성능은 CPU보다 떨어지지만, 그 대신 엄청난 병렬성을 활용하여 전체 처리량을 극대화할 수 있다.

이 차이는 아래 그림을 통해 더 명확히 확인할 수 있다.

![alt text](/CUDA_cpp_Programming/Images/Figure1.png)

위 그림에서, CPU는 코어와 캐시, 제어 장치(Control Logic)에 상당한 면적을 투자한다. 반면 GPU는 대부분의 트랜지스터를 연산 코어에 집중 배치한다. 제어와 캐시 자원을 최소화하고, 대신 수많은 데이터 병렬 연산을 동시에 실행할 수 있도록 설계된 것이다.

### GPU의 강점: 병렬 연산 최적화
GPU가 더 많은 트랜지스터를 **데이터 처리(floating-point 연산 등)**에 투입한 것은 병렬 연산에서 큰 장점을 제공한다.

CPU는 긴 메모리 지연(Latency)을 줄이기 위해 큰 캐시와 복잡한 제어 방식을 사용한다. 반면 GPU는 접근 방식이 다르다. GPU는 메모리 지연을 "숨기기(hide)" 위해 연산을 병렬로 수행한다. 즉, 어떤 스레드가 메모리를 기다리는 동안 다른 스레드들이 연산을 이어나감으로써 전체 처리 속도를 떨어뜨리지 않는 것이다.

이 방식은 많은 수의 스레드가 동시에 실행될 수 있기 때문에 가능하며, GPU를 **고도로 병렬화된 계산**에 적합한 구조로 만들어준다.

### CPU와 GPU의 협력
대부분의 응용 프로그램은 **순차적 부분과 병렬적 부분**을 모두 가지고 있다. 따라서 전체 성능을 극대화하려면 CPU와 GPU를 혼합해서 사용하는 것이 바람직하다.
 - CPU는 복잡한 제어와 순차적 연산에 강하다.
 - GPU는 병렬성이 높은 부분을 압도적으로 빠르게 처리할 수 있다.
따라서 **고도의 병렬성을 지닌 연산**을 수행하는 응용 프로그램은 GPU의 특성을 적극 활용함으로써 CPU만 사용할 때보다 훨씬 높은 성능을 얻을 수 있다.

---

## CUDA®: 범용 병렬 컴퓨팅 플랫폼과 프로그래밍 모델
2006년 11월, NVIDIA는 **CUDA®(Compute Unified Device Architecture)**를 처음 세상에 내놓았다. CUDA는 단순히 그래픽 처리에 국한된 기술이 아니라, GPU 내부에 존재하는 병렬 연산 엔진을 활용하여 **범용적인 계산 문제를 해결할 수 있는 병렬 컴퓨팅 플랫폼**이자 **프로그래밍 모델**이다.

기존에는 복잡한 수치 계산을 CPU에서 수행했지만, 많은 경우 CPU는 직렬 연산에 최적화되어 있어 한계가 있었다. CUDA는 GPU의 막대한 병렬 처리 능력을 활용하되, 동일한 문제를 훨씬 효율적으로 해결할 수 있게 해주었다.

### CUDA 소프트웨어 환경
CUDA의 또 다른 강점은 개발자가 익숙한 **C++ 언어**를 그대로 사용할 수 있다는 점이다. GPU를 직접 다루는 복잡한 어셈블리 수준 프로그래밍 대신, C++ 문법을 확장하여 GPU 병렬 코드를 작성할 수 있도록 지원한 것이다. 이로써 연구자와 개발자들은 새로운 언어를 배우지 않고도 GPU의 성능을 활용할 수 있게 되었다.

또한 CUDA는 단지 C++에 국한되지 않는다. 아래 그림에서 보듯이, CUDA는 다양한 언어와 프로그래밍 접근 방식을 지원한다.
 - **Fortran** 같은 과학 연산용 언어
 - **DirectCompute** 같은 그래픽스 API 기반 접근
 - **OpenACC** 같은 지시문(directive) 기반 병렬화 방식

![alt text](/CUDA_cpp_Programming/Images/Figure2.png)

이를 통해 다양한 분야의 개발자들이 자신의 기존 코드와 워크 플로우를 크게 변경하지 않고 GPU 가속을 적용할 수 있다.

즉, CUDA는 GPU를 단순한 그래픽 처리 장치가 아닌, **범용 병렬 계산 장치**로 탈바꿈시킨 중요한 전환점이다. 오늘날 딥러닝, 과학 시뮬레이션, 금융 모델링, 영상 처리 등 수많은 분야에서 CUDA는 GPU의 성능을 실질적으로 활용할 수 있는 핵심 도구로 자리 잡고 있다.

---

## Scalable(확장 가능한) 프로그래밍 모델
멀티코어 CPU와 다중 코어(manycore) GPU가 보편화되면서, 오늘날의 프로세서는 기본적으로 **병렬 시스템**으로 진화하였다. 이제 과제는, 프로세서 코어 개수가 증가하더라도 **응용 프로그램이 자동으로 그 병렬성을 활용할 수 있도록 만드는 것**이다.

3D 그래픽스 응용이 수십, 수백 개의 GPU 코어를 자동으로 활용하는 것처럼, 일반 응용 프로그램도 비슷하게 확장성 있는 실행 방식을 가져야 하는 것이다.

### CUDA 프로그래밍 모델의 설계 목표
CUDA 병렬 프로그래밍 모델은 이러한 도전을 해결하기 위해 고안되었다.
중요한 점은, C와 같은 **표준 프로그래밍 언어**에 이미 익숙한 개발자가 쉽게 접근할 수 있도록 **낮은 학습 곡선**을 유지했다는 것이다.

CUDA 모델의 핵심은 세 가지 추상화이다.
 - **스레드 그룹 계층 구조(Hierarchy of Thread Groups)**
 - **공유 메모리(Shared Memories)**
 - **베리어 동기화(Barrier Synchronization)**

이 세 가지는 최소한의 언어 확장으로 프로그래머에게 제공되며, 이를 통해 **세밀한 데이터 병렬성과 스레드 병렬성**을 표현할 수 있다.

### 문제 분할과 협력적 병렬 처리
CUDA는 문제를 자연스럽게 **계층적 구조**로 분할할 수 있게 돕는다.
큰 문제를 **블록 단위(sub-problem)**로 나누어 서로 독립적으로 처리한다. 각 블록 내부에서는 다시 문제를 더 작은 단위로 나누어, **스레드들이 협력적으로(cooperatively) 병렬 실행**을 수행한다.

이러한 구조는 다음과 같은 두 가지 장점을 갖는다.
 - **언어 표현력 보존** : 스레드들이 협력할 수 있으므로 복잡한 문제를 해결 가능하다.
 - **자동 확장성 보장** : 각 블록은 GPU의 어떤 멀티 프로세서(SM)에도 배치될 수 있으므로, GPU의 SM 수에 따라 프로그램은 자연스럽게 확장된다.

### GPU의 기본 구조: Streaming Multiprocessors
GPU는 **Streaming Multiprocessors(SM)**라고 불리는 처리 단위들이 격자처럼 배열된 구조를 가지고 있다. 각각의 SM은 수십 개의 연산 코어와 자체적인 레지스터, 공유 메모리 등을 포함하고 있으며, 병렬 연산을 실제로 수행하는 핵심 단위이다.

CUDA에서 작성된 다중 스레드 프로그램은 **스레드 블록(block of threads)** 단위로 나누어진다.
각 블록은 독립적으로 실행될 수 있기 때문에, 다른 블록과의 직접적인 동기화 없이 작업을 처리한다. 이 덕분에 블록은 GPU 내부의 어떤 SM에 배치되더라도 문제없이 실행될 수 있다.

즉, GPU는 프로그램을 블록 단위로 잘게 쪼개어 SM에 배치하고, 하드웨어는 이 블록들을 자동으로 스케줄링하여 실행하게 된다.

![alt text](/CUDA_cpp_Programming/Images/Figure3.png)

이러한 구조는 GPU 성능 확장의 핵심이다. 
SM 개수가 많은 GPU는 **더 많은 블록을 동시에 실행**할 수 있어 전체 프로그램을 더 빨리 처리한다. 반대로 SM  개수가 적은 GPU라도 동일한 프로그램은 동작하며, 다만 블록을 순차적으로 더 오래 실행해야 하므로 시간이 조금 더 걸릴 뿐이다.

즉, **프로그램은 GPU의 하드웨어 규모를 몰라도 된다**는 것이 장점이다. 개발자는 블록 단위 병렬성을 정의하기만 하면, 실행 속도의 차이는 GPU에 탑재된 SM 수가 자동으로 결정해준다.

정리하자면, GPU는 **SM 배열 구조를 기반**으로 하며, 스레드 블록의 독립성 덕분에 **SM 개수와 상관 없이 동일한 프로그램을 실행할 수 있고,** SM이 많을수록 더 빠른 실행이 가능하다.